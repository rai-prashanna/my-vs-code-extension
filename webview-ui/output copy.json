{"Summary": "AuthTokenService centralizes the lifecycle of short-lived authentication tokens by creating, storing, rotating, validating, and reading token payloads in Redis so controllers can request or verify user tokens without handling storage or expiration logic themselves.", "Relationships": [{"Operation": "AuthTokenService", "Description": "Manages token generation, storage, rotation, existence checks, and payload retrieval in Redis for a given user; controllers can call its methods to obtain a valid token for a user, validate an incoming token, or read the token payload while keeping Redis access and TTL handling out of controller code."}], "file": "app/services/auth_token_service.txt"}
{"Summary": "ApplicationService acts as a shared base for concrete service classes, centralizing current user and request context, Pundit authorization hooks, parameter handling, and change-reason validation so controllers and operation classes can delegate business rules to services while models are inspected via policies and controllers remain focused on request/response orchestration.", "Relationships": [], "file": "app/services/application_service.txt"}
{"Summary": "ImportProfileService centralizes the work of turning an uploaded JSON file into persisted profile records by parsing and validating the file, resolving Protocol and ProtocolsVariable references, building the appropriate Profile subclass data (segments or parameters), ensuring unique names, and returning a ServiceResult for controllers to render success or error feedback, and its purpose is to keep parsing and persistence logic out of controllers and encapsulated in one import-focused service.", "Relationships": [{"Model": "Profile", "Description": "The service builds a Profile instance (including assigning name, description, organization_id and type) from the JSON and persists it; controllers can call the service to perform the full import and then use the returned ServiceResult to decide how to respond to the user.", "Operation": null, "OperationDescription": null}, {"Model": "Protocol", "Description": "ImportProfileService looks up a Protocol by name and either ver or ver_string and stores its id on the importing profile, returning clear errors if the protocol or version is missing; controllers rely on the service to validate and fetch protocol references during import.", "Operation": null, "OperationDescription": null}, {"Model": "ProtocolsVariable", "Description": "The service resolves protocol variable names into ProtocolsVariable ids and attaches them to profiles_variables with value, is_editable, and is_visible attributes so the imported profile links to existing protocol variables; controllers therefore do not need to implement variable lookup logic.", "Operation": null, "OperationDescription": null}, {"Model": "CeresProfile", "Description": "When the imported type is CeresProfile the service uses a special save path that calls save_with_delayed_validation and returns success or the profile errors accordingly, allowing controllers to handle this profile subtype uniformly via the service result.", "Operation": null, "OperationDescription": null}, {"Model": "FreezingProfile / ExtractorProfile / ThawingProfile", "Description": "For FreezingProfile and ExtractorProfile the service constructs segments from the JSON and for ThawingProfile it assigns parameter settings, so controllers can delegate type-specific construction to the service instead of duplicating import logic.", "Operation": null, "OperationDescription": null}, {"Model": null, "Description": null, "Operation": "ParameterUploader", "OperationDescription": "The service uses ParameterUploader to cache and validate the uploaded file and converts uploader integrity errors into ServiceResult failures so controllers get an early, clear failure reason for bad uploads."}], "file": "app/services/import_profile_service.txt"}
{"Summary": "EquipmentService centralizes the create and update workflows for Equipment and its associated device User by preparing and assigning attributes, tags, parent relationships, LDAP settings, and API credentials while calling helper operations (type resolution and password generation), so controllers can invoke a single service to perform these domain tasks instead of embedding detailed model logic.", "Relationships": [{"Model": "Equipment", "Description": "Used by the service to determine the Equipment 'type', which guides how parameters are interpreted and which attributes or templates (for example LDAP fields) are applied.", "Operation": "EquipmentStrategy"}, {"Model": "User", "Description": "Produces the API password value that the service assigns to the Equipment and its device User during creation.", "Operation": "PasswordGenerator"}], "file": "app/services/equipment_service.txt"}
{"Summary": "ServiceResult is a lightweight utility that encapsulates the outcome and optional payload of service calls so controllers and service classes can return a consistent success flag and data without mixing result handling into business logic or models.", "Relationships": [], "file": "app/services/service_result.txt"}
{"Summary": "UserService centralizes user creation and update workflows by performing authorization, sanitizing and assigning incoming parameters (tags, organization, username, workdays, email), generating temporary passwords, enforcing subscription and change-reason rules, and returning structured outcomes so controllers can remain thin and use the service to handle business logic and decide redirects/notices while the User model remains focused on persistence.", "Relationships": [{"Model": "User", "Description": "UserService builds or loads User records, sets organization and tags, assigns usernames and temporary passwords, enforces subscription and change-reason validations, updates attributes with or without password changes, and returns success/notice/redirect information that controllers can use to decide how to respond to user-facing requests."}, {"Operation": "PasswordGenerator", "Description": "UserService calls PasswordGenerator to produce a secure temporary password for new users so controllers do not need to handle password creation logic directly."}, {"Operation": "policy(User)", "Description": "UserService relies on the User policy to determine permitted attributes and to perform authorization checks before creating or updating users, allowing controllers to delegate permission and parameter rules to policy-driven logic."}], "file": "app/services/user_service.txt"}
{"Summary": "TwilioNumberSelector encapsulates the logic to pick the correct Twilio from-number by using Twilio Lookup and Redis caching to determine if a receiver is US-based, keeping lookup and caching concerns out of controllers and models so controllers can simply call the service to get the appropriate from-number when sending messages.", "Relationships": [{"Operation": "Twilio Lookup (lookups.v1.phone_numbers.fetch)", "Description": "The TwilioNumberSelector calls the Twilio Lookup API to obtain a phone number's country code; controllers can rely on the service to perform this external lookup and return a decision about which Twilio number to use for sending."}, {"Operation": "Redis (REDIS.get / REDIS.set)", "Description": "The service caches country codes in Redis to avoid repeated external lookups and improve performance; controllers benefit from faster, cached responses without needing to manage caching themselves."}], "file": "app/services/twilio_number_selector.txt"}
{"Summary": "This snippet defines a custom BiosafeManager::UnsupportedFileTypeError that builds a localized \"unsupported file type\" message for a given filename so file-processing services or operations can raise a clear exception that controllers or other parts of the application can catch and handle consistently.", "Relationships": [], "file": "app/services/biosafe_manager/unsupported_file_type_error.txt"}
{"Summary": "Service classes encapsulate normalization logic, and BiosafeManager::FixNumericConvention inspects a provided ActiveRecord model class to convert comma-delimited numeric strings in a result hash to integers or floats so controllers or other callers can sanitize input and prepare data for persistence while keeping casting logic out of models and controllers.", "Relationships": [{"Model": "result_class (ActiveRecord model)", "Description": "The service uses the provided model class to look up attribute types and decide whether values in the result hash should be cast to integer or float; controllers can pass the target model class so values match column types before saving."}, {"Operation": "BiosafeManager::FixNumericConvention", "Description": "A service that normalizes numeric-formatted strings in a hash based on the given model's attribute types, intended to be called by controllers or other services to sanitize and prepare data for persistence."}], "file": "app/services/biosafe_manager/fix_numeric_convention.txt"}
{"Summary": "The BiosafeManager::ExtractStartTime service centralizes the logic to parse a start time encoded at the end of a procedure reference using the related Equipment time zone so that controllers can call this service to get a parsed Time or nil and keep parsing logic out of models and controllers.", "Relationships": [{"Model": "Equipment", "Description": "This service takes a record with a procedure_ref, tries multiple date formats at the end of that string, and returns a parsed Time or nil; controllers should call this operation to handle parsing and keep their actions focused on request/response logic.", "Operation": "BiosafeManager::ExtractStartTime"}], "file": "app/services/biosafe_manager/extract_start_time.txt"}
{"Summary": "The BiosafeManager::FinalUpdates service centralizes the end-of-life workflow for a Datum by reading its equipment results, updating the first and last result records, and dispatching webhooks so controllers can invoke a single, focused class to persist measurement changes and trigger notifications instead of embedding that logic in models or controllers.", "Relationships": [{"Model": "Datum", "Description": null, "Operation": null}, {"Model": "EquipmentResult", "Description": null, "Operation": null}], "file": "app/services/biosafe_manager/final_updates.txt"}
{"Summary": "BiosafeManager::GetFileType is a focused service that determines whether an uploaded file is a log, a pat, or unsupported by checking the filename extension and inspecting the UTF-8-converted file content, delegating encoding conversion to ConvertFileBodyToUtf8 so controllers can call this service to decide how to validate or route incoming files.", "Relationships": [{"Operation": "ConvertFileBodyToUtf8", "Description": "GetFileType calls this operation to convert the raw file body to UTF-8 before examining lines and tab-separated fields; controllers can rely on GetFileType (which uses this operation) to obtain a stable file-type result and then choose the appropriate processing or validation flow for uploaded files."}], "file": "app/services/biosafe_manager/get_file_type.txt"}
{"Summary": "The BiosafeManager::FileImport service coordinates file parsing, document persistence, model updates, event creation, and webhook delivery by delegating parsing to device-specific parser classes and calling SaveDocument so controllers can invoke a single service to handle import workflows while keeping parsing, persistence, and status transitions separated.", "Relationships": [{"Model": "Datum", "Description": "SaveDocument is called by the service to persist the uploaded file contents for the Datum so the file is stored separately from parsing and status logic.", "Operation": "SaveDocument"}, {"Model": "Datum", "Description": "The device-specific PatParser is invoked to extract measurements or warnings from PAT files and append results or events to the Datum used by the service to decide completion.", "Operation": "BiosafeManager::<Device>::PatParser"}, {"Model": "Datum", "Description": "The device-specific LogParser parses LOG files to produce equipment_results or events on the Datum that the service then evaluates to update state or trigger webhooks.", "Operation": "BiosafeManager::<Device>::LogParser"}, {"Model": "Event", "Description": "The FileImport service's unsupported_file branch constructs and saves Event records to capture import errors, centralizing error recording within the import workflow.", "Operation": "BiosafeManager::FileImport"}], "file": "app/services/biosafe_manager/file_import.txt"}
{"Summary": "The FileInit service centralizes the file intake workflow by validating and uploading a submitted equipment file, normalizing and classifying its content, resolving a device-specific procedure reference, and finding or creating the associated datum in the context of an Equipment record so controllers can call a single service to handle all file-processing responsibilities and keep their code simple.", "Relationships": [{"Model": "Equipment", "Description": "FileInit uses the given Equipment instance to scope the upload (equipment.serialnum) and to read device_type so the file can be stored and interpreted in the right device context; controllers can call FileInit with an Equipment to attach an uploaded file to that equipment."}, {"Model": "Datum", "Description": "The service ensures the uploaded file is linked to a domain record (datum) for the equipment and procedure, so controllers receive or act on the persistent datum instead of handling raw file linkage themselves."}, {"Operation": "FogFileAccess", "Description": "Handles storage concerns: FileInit asks FogFileAccess to create a uniquely prefixed file path and upload the file body to fog storage, keeping storage and naming logic out of controllers and models."}, {"Operation": "ConvertFileBodyToUtf8", "Description": "Normalizes the raw uploaded bytes to UTF-8 before other processing so downstream steps can reliably inspect and parse file content."}, {"Operation": "GetFileType", "Description": "Determines the file type from filename and normalized content so the service can decide how to interpret the file and which device-specific procedure lookup to run."}, {"Operation": "BiosafeManager::<DeviceType>::GetProcedureRef", "Description": "A device-specific operation selected via the equipment's device_type that derives the procedure reference from filename, body, and file type so the file can be associated with the correct domain procedure."}, {"Operation": "FindOrCreateDatum", "Description": "Finds or creates the datum record that links the equipment and the resolved procedure_ref, encapsulating persistence logic so controllers do not need to manage creation or lookup details."}], "file": "app/services/biosafe_manager/file_init.txt"}
{"Summary": "Service classes (for example BiosafeManager::GetPatValue) encapsulate mapping and extraction logic so controllers or other callers can request a PAT field value by passing in device type and results, keeping controllers thin and models focused on persistence and database concerns.", "Relationships": [{"Operation": "BiosafeManager::GetPatValue", "Description": "This service holds a device-type-to-field mapping and extracts the matching PAT value from a provided results array; controllers or higher-level services can call it to get a specific field value without needing to know the mapping details or inspect raw result structures."}], "file": "app/services/biosafe_manager/get_pat_value.txt"}
{"Summary": "The BiosafeManager::FindOrCreateDatum service encapsulates the logic to locate or create a Datum record tied to a given Equipment and procedure reference so controllers can call a single, reusable routine to ensure the appropriate Datum exists before continuing workflow or persistence tasks.", "Relationships": [{"Model": "Datum", "Description": null, "Operation": null}, {"Model": "Equipment", "Description": null, "Operation": null}], "file": "app/services/biosafe_manager/find_or_create_datum.txt"}
{"Summary": "The BiosafeManager::GetEventsFromPat service converts raw PAT transaction results into Event objects by classifying codes as errors or warnings using provided code ranges, so controllers can call this operation to turn external PAT data into domain Event instances for persistence or display while keeping classification logic out of the models.", "Relationships": [{"Model": "Event", "Description": "This operation accepts PAT results, a datum, and error/warning code ranges, filters transaction-type entries, checks each code against the ranges to classify it, and returns Event objects representing warnings or errors for downstream use.", "Operation": "BiosafeManager::GetEventsFromPat"}], "file": "app/services/biosafe_manager/get_events_from_pat.txt"}
{"Summary": "The BiosafeManager::CheckEmptyLog service centralizes the check that a parsed CSV log for a given Datum contains no data rows and creates a warning Event when empty, so controllers or higher-level code can call this single responsibility service to validate uploads and record audit warnings without mixing that logic into request handling or models.", "Relationships": [{"Model": "Event", "Description": "The service creates an Event record of type 'warning' and links it to equipment, datum, and organization when it detects an empty CSV; controllers can invoke the service to produce audit or warning events instead of creating Events themselves."}, {"Model": "Datum", "Description": "The service reads attributes from a given Datum instance (id, equipment_id, organization_id) to associate the warning with the correct context; controllers should pass the parsed Datum to the service when validating uploaded logs."}, {"Operation": "BiosafeManager::CheckEmptyLog", "Description": "This operation receives a Datum and CSV rows, checks whether the CSV contains only a header, and triggers Event creation when empty, providing a reusable, centralized place for empty-log validation and side effects that controllers or other services can call."}], "file": "app/services/biosafe_manager/check_empty_log.txt"}
{"Summary": "The BiosafeManager::SaveDocument service centralizes the logic for creating device-linked documents (ensuring no duplicates and applying permission scope), so controllers can pass a datum and file and rely on the service to handle model lookups, permission checks, and record creation.", "Relationships": [{"Model": "Document", "Description": "The service checks for an existing Document tied to a specific datum and equipment and creates a new Document record with the file and metadata if none exists; controllers can call the service to persist uploaded files without embedding creation logic in controllers.", "Operation": "BiosafeManager::SaveDocument", "OperationDescription": "Encapsulates the create-if-not-exists workflow for Document persistence, including preparing file data and notes, so callers get a single, reusable operation for saving documents."}, {"Model": "Datum", "Description": "Datum is used as the contextual source of truth (its id links the document) and the service reads datum to determine the target equipment and to scope the lookup for duplicates; controllers supply the datum when delegating the save action to the service.", "Operation": "BiosafeManager::SaveDocument", "OperationDescription": "Takes a datum instance as input to derive association information and to drive the document save flow, keeping controllers free from association and validation details."}, {"Model": "Equipment", "Description": "The service uses Equipment via datum.equipment to attach organization and equipment identifiers, to build descriptive notes, and to enforce policy scope for visible documents; controllers benefit by not having to manage equipment-related attributes or permission checks when saving a document.", "Operation": "BiosafeManager::SaveDocument", "OperationDescription": "Reads equipment-related data and applies policy-scoped lookups to prevent unauthorized or duplicate document creation, centralizing permission-aware business rules."}], "file": "app/services/biosafe_manager/save_document.txt"}
{"Summary": "The BiosafeManager::ConvertFileBodyToUtf8 service centralizes file-encoding conversion so controllers and other services can normalize uploaded file content to UTF-8 before further processing or persistence, illustrating a separation of concerns where services handle processing, models handle persistence, and controllers orchestrate flows.", "Relationships": [{"Model": "", "Operation": "BiosafeManager::ConvertFileBodyToUtf8", "Description": "No explicit ActiveRecord model is involved; this service operates on raw file body data to detect UTF-16 BOMs, force encodings, and return valid UTF-8 content so controllers or higher-level operations can safely process or persist uploaded files without encoding errors."}], "file": "app/services/biosafe_manager/convert_file_body_to_utf8.txt"}
{"Summary": "Service classes encapsulate focused parsing or business logic so controllers or other services can call them without cluttering models or controllers; in this code the BiosafeManager::GetProcedureRefFromFilename service extracts a standardized procedure reference from a filename (using a BIOSAFE pattern or falling back to basename components) so callers can get a clean identifier for later loading, storing, or routing of data.", "Relationships": [{"Operation": "BiosafeManager::GetProcedureRefFromFilename", "Description": "This service isolates filename parsing and returns a procedure reference by matching a BIOSAFE pattern or splitting the file basename; controllers or higher level services can call it to obtain a normalized procedure id before interacting with models or deciding response behavior, keeping parsing logic out of controllers and models."}], "file": "app/services/biosafe_manager/get_procedure_ref_from_filename.txt"}
{"Summary": "The BiosafeManager::CheckTrailingPat service centralizes the logic to inspect equipment log files for a trailing PAT procedure ID, uses a conversion operation to normalize file content, and creates Event warnings when the PAT is missing so controllers or background jobs can call this service to enforce data completeness without embedding pattern checks or event creation logic themselves.", "Relationships": [{"Model": "Event", "Description": "The service creates an Event record with a warning when a required trailing PAT procedure ID is not found, allowing controllers to rely on the service to persist warnings rather than handling event creation directly."}, {"Operation": "ConvertFileBodyToUtf8", "Description": "The service calls this operation to normalize the uploaded file body into UTF-8 before searching for PAT patterns, so controllers do not need to handle encoding issues."}, {"Operation": "BiosafeManager::CheckTrailingPat", "Description": "This service encapsulates equipment-specific pattern checks and the decision to create warning Events, and can be invoked by controllers or background workers to validate logs and centralize that business rule."}], "file": "app/services/biosafe_manager/check_trailing_pat.txt"}
{"Summary": "The PatParser service orchestrates a parsing workflow by converting file encoding, using a file parser, extracting named values, and generating events to populate and save a MyDatum record; its purpose is to encapsulate PAT file parsing and mapping so controllers can call a single service to persist protocol metadata and attach warning/error events.", "Relationships": [{"Model": "MyDatum", "Description": "Called first to normalize the file body encoding before parsing; a controller does not need to handle encoding concerns because the service uses this operation internally.", "Operation": "BiosafeManager::ConvertFileBodyToUtf8"}, {"Model": "MyDatum", "Description": "Performs the raw parsing of the file body into structured lines that the service reads to populate MyDatum and drive subsequent extraction and event generation.", "Operation": "PatFileParser"}, {"Model": "MyDatum", "Description": "Queried repeatedly for keys like volume, container, operator, and protocol to extract the exact values that are then written into MyDatum attributes.", "Operation": "BiosafeManager::GetPatValue"}, {"Model": "MyDatum", "Description": "Generates event records from the parsed content using predefined error and warning code ranges and returns them so the service can attach them to MyDatum for downstream handling.", "Operation": "BiosafeManager::GetEventsFromPat"}], "file": "app/services/biosafe_manager/sepax2/pat_parser.txt"}
{"Summary": "This service centralizes file-processing responsibilities by normalizing encoding, delegating parsing and value extraction to focused operations, and falling back to filename-based extraction so controllers can call one service to obtain a procedure reference while keeping parsing logic out of models and controllers.", "Relationships": [{"Operation": "BiosafeManager::ConvertFileBodyToUtf8", "Description": "The service uses this operation to ensure the file body is UTF-8 before any parsing, so controllers can rely on the service to handle encoding issues and do not need to preprocess file contents."}, {"Operation": "PatFileParser", "Description": "The service instantiates and uses this parser to extract structured lines from PAT files, letting controllers get parsed data via the service without handling parsing logic themselves."}, {"Operation": "BiosafeManager::GetPatValue", "Description": "After parsing, the service calls this operation to extract the Sepax2 procedure_ref value from parsed PAT results, providing a clear path from raw file to domain value for controllers."}, {"Operation": "BiosafeManager::GetProcedureRefFromFilename", "Description": "This operation is used as a fallback to derive a procedure reference from the filename when the file body does not contain the value, so controllers receive a best-effort result regardless of file contents."}, {"Operation": "BiosafeManager::UnsupportedFileTypeError", "Description": "The service raises this error for unrecognized file types, keeping validation and error signaling centralized so controllers can handle failures uniformly."}], "file": "app/services/biosafe_manager/sepax2/get_procedure_ref.txt"}
{"Summary": "The BiosafeManager::Sepax2::LogParser service centralizes the end-to-end work of converting and parsing a Sepax2 log file, delegating helper operations, creating warnings or errors, updating equipment and datum metadata, and importing measurement records so controllers can trigger a single, high-level action to process uploaded logs and keep business logic out of models and controllers.", "Relationships": [{"Model": "ResultSepax2", "Description": "The parser builds and batches measurement attribute hashes from the log rows, normalizes numeric formats, and imports those batches into ResultSepax2 so controllers can rely on the service to populate measurement records."}, {"Model": "Event", "Description": "The parser creates Event records for error or warning conditions (missing header, multiple abrupt interruption markers) to surface issues for users and audit trails instead of scattering that logic elsewhere."}, {"Model": "Equipment", "Description": "The parser reads the equipment time zone to interpret timestamps and updates the equipment software_version when present, letting controllers depend on the service to keep equipment metadata current."}, {"Operation": "BiosafeManager::ConvertFileBodyToUtf8", "Description": "Used up front to ensure the incoming file body is in UTF-8 encoding before any parsing, so the service can work with consistent text."}, {"Operation": "BiosafeManager::CheckTrailingPat", "Description": "Called to inspect and handle trailing patterns related to the datum and equipment context as part of log validation and cleanup."}, {"Operation": "BiosafeManager::CheckEmptyLog", "Description": "Used after parsing to detect and short-circuit processing for empty or invalid logs, letting the service stop further work and surface the condition."}, {"Operation": "BiosafeManager::FixNumericConvention", "Description": "Applied to each result hash to normalize numeric formats before importing, so the import step receives clean numeric values."}, {"Operation": "BiosafeManager::FinalUpdates", "Description": "Called at the end to perform any remaining updates on the datum after results are imported, consolidating post-import housekeeping in one place."}], "file": "app/services/biosafe_manager/sepax2/log_parser.txt"}
{"Summary": "The PatParser service centralizes PAT file parsing and orchestration by calling focused operation classes to normalize and extract data, updating and saving MyDatum and related Equipment records and attaching Event objects so controllers can simply invoke the service to handle PAT file uploads without embedding parsing or event logic in models.", "Relationships": [{"Model": "MyDatum", "Description": "PatParser takes a MyDatum instance, populates metadata fields (extended_header, start_time, profile_container, profile_fill, comment, operator_instrument), saves the record, and appends generated events so controllers can get a fully populated MyDatum after processing a PAT file."}, {"Model": "Equipment", "Description": "PatParser updates the associated Equipment software_version when present in the PAT content, keeping equipment metadata in sync as part of the parsing workflow invoked by controllers."}, {"Operation": "BiosafeManager::ConvertFileBodyToUtf8", "Description": "Normalizes the incoming file body encoding to UTF-8 so downstream parsers receive consistent text."}, {"Operation": "XmlPatFileParser", "Description": "Parses the normalized PAT XML into structured lines/blocks that downstream extractors and validators use to populate models and generate events."}, {"Operation": "BiosafeManager::GetPatValue", "Description": "Extracts specific PAT values (for example volume, container, software_ver, operator, protocol) from the parsed lines so PatParser can set corresponding MyDatum attributes."}, {"Operation": "BiosafeManager::ExtractStartTime", "Description": "Derives the start_time for the MyDatum from parsed content so the timestamp logic is kept out of the model and controller."}, {"Operation": "BiosafeManager::GetEventsFromPat", "Description": "Analyzes parsed lines against configured error and warning code ranges and returns Event records that PatParser attaches to MyDatum to reflect warnings or errors."}], "file": "app/services/biosafe_manager/sefia/pat_parser.txt"}
{"Summary": "The BiosafeManager::Sefia::GetProcedureRef service centralizes the workflow to extract a procedure reference from PAT or log files by normalizing file encoding, parsing PAT XML, querying parsed values, and falling back to filename-based extraction while surfacing validation errors, so controllers can call a single, well-scoped service to get a validated procedure reference without embedding parsing or encoding logic.", "Relationships": [{"Operation": "BiosafeManager::ConvertFileBodyToUtf8", "Description": "Normalizes raw file contents to UTF-8 before any parsing; GetProcedureRef uses this so controllers do not need to handle encoding issues when accepting uploaded files."}, {"Operation": "XmlPatFileParser", "Description": "Parses PAT XML content into structured lines that the service can inspect; GetProcedureRef delegates XML parsing to this class so controllers avoid XML handling and remain focused on request/response flow."}, {"Operation": "BiosafeManager::GetPatValue", "Description": "Queries parsed PAT data for the specific :procedure_ref field; GetProcedureRef calls this to retrieve the named value and controllers can rely on the service to return the domain value if present."}, {"Operation": "BiosafeManager::GetProcedureRefFromFilename", "Description": "Derives a procedure reference from the filename as a fallback when file content does not provide one; GetProcedureRef uses this fallback so controllers receive a best-effort reference without implementing their own filename parsing."}], "file": "app/services/biosafe_manager/sefia/get_procedure_ref.txt"}
{"Summary": "The BiosafeManager::Sefia::LogParser service encapsulates the end-to-end work of turning an uploaded log file into database records by calling focused helper operations for encoding, validation, time extraction, numeric fixes, and final updates while updating a MyDatum record and bulk importing many ResultSefia rows so controllers can simply hand a MyDatum and file to it and get parsed, persisted results.", "Relationships": [{"Model": "MyDatum", "Description": "ExtractStartTime is used to compute the MyDatum start_time, CheckTrailingPat validates the file against the equipment and MyDatum state before parsing, CheckEmptyLog can stop processing if no useful rows are found, and FinalUpdates applies post-import updates tied to the MyDatum.", "Operation": "BiosafeManager::ExtractStartTime, BiosafeManager::CheckTrailingPat, BiosafeManager::CheckEmptyLog, BiosafeManager::FinalUpdates"}, {"Model": "ResultSefia", "Description": "FixNumericConvention normalizes numeric formatting for ResultSefia attributes before saving, and ResultSefia.import is used to efficiently bulk insert the prepared records into the database.", "Operation": "BiosafeManager::FixNumericConvention, ResultSefia.import"}], "file": "app/services/biosafe_manager/sefia/log_parser.txt"}
{"Summary": "The ChromatogramManager::ChartChromatogramData service centralizes paginated fetching and basic aggregation of chromatogram curve data (volume and amplitude and initial max counts) so controllers can request ready-to-use graph data and metadata without embedding query or pagination logic in controllers or models.", "Relationships": [{"Operation": "ChromatogramManager::ChartChromatogramData", "Description": "This service takes a queryable results set, an offset, request parameters, and curve mapping, and returns per-curve sliced records (volume and amplitude) plus initial max counts when offset is zero; controllers can call it to obtain paginated chart data and simple metadata for rendering graphs or APIs instead of performing these queries themselves."}], "file": "app/services/chromatogram_manager/chart_chromatogram_data.txt"}
{"Summary": "Service classes like OpcManager::PrepareUnicornData centralize data-preparation tasks (computing missing timestamps, selecting needed fields, paginating and sorting records) so controllers can request ready-to-use time-ordered records while models such as Datum provide the raw timestamps and identifiers, keeping responsibilities separated and easy to reuse.", "Relationships": [{"Model": "Datum", "Description": "This operation prepares result records by ensuring each has a logged_at (computing it from an hour field and the Datum start_time when missing), selecting the required fields, applying offset/limit, and returning results sorted by time so controllers get consistent, presentation-ready data for charts or reports.", "Operation": "OpcManager::PrepareUnicornData"}], "file": "app/services/opc_manager/prepare_unicorn_data.txt"}
{"Summary": "OpcManager::CheckUnicornData is a focused service that checks a collection of result records for any non-nil values in specified hourly fields so controllers can ask a single, testable operation whether 'unicorn' data exists and keep querying logic out of controllers and models.", "Relationships": [{"Operation": "OpcManager::CheckUnicornData", "Description": "Takes a collection of result records and a list of hour field names, runs queries across those fields to detect any non-nil values, and returns a boolean; controllers can call this operation to drive decisions like validation, filtering, or conditional rendering without performing the queries themselves."}], "file": "app/services/opc_manager/check_unicorn_data.txt"}
{"Summary": "The OpcManager::DeleteRealTimeResults service encapsulates the logic that monitors a Datum's saved results count and, when it equals the expected value, schedules the DeleteXuriRealTimeDataJob to remove those real-time results\u2014demonstrating a clear separation where models hold the data, services coordinate decisions, and background operations perform the work so controllers can simply invoke the service.", "Relationships": [{"Model": "Datum", "Description": "This service contains the decision-making logic (compare saved versus expected results) and is the entry point other parts of the app call to schedule cleanup.", "Operation": "OpcManager::DeleteRealTimeResults"}, {"Model": "Datum", "Description": "The service enqueues this background job to perform the actual deletion asynchronously, keeping request-time code lightweight and responsive.", "Operation": "DeleteXuriRealTimeDataJob"}], "file": "app/services/opc_manager/delete_real_time_results.txt"}
{"Summary": "The OpcManager::AddTimeZone service centralizes timezone handling by taking an equipment (whose time_zone it reads) and a date and returning the date converted into the equipment timezone or nil, so controllers can call it to obtain a correctly zoned timestamp before persisting or further processing, keeping timezone conversion logic out of models and controllers.", "Relationships": [{"Model": "Equipment", "Description": "This service accepts an equipment and a date, returns the date adjusted to the equipment time zone using in_time_zone or nil if the date is missing, encapsulating timezone conversion so other layers do not need to implement that logic.", "Operation": "OpcManager::AddTimeZone"}], "file": "app/services/opc_manager/add_time_zone.txt"}
{"Summary": "The OpcManager::FindOrCreateDatum service centralizes the workflow of locating an existing Datum by procedure_ref for a given Equipment user or creating a new in-progress Datum with provided attributes and triggering a follow-up alert operation, so controllers can call this single service to keep request handling simple while models persist data and operations handle side effects.", "Relationships": [{"Model": "Datum", "Description": "The service queries for an existing Datum by procedure_ref and, when none is found and a start_time is provided, creates a new in-progress Datum record with provided attributes and associations so controllers can rely on the service to ensure a single up-to-date datum exists for a procedure."}, {"Model": "Equipment", "Description": "The service accepts an Equipment instance to scope the search to the equipment's user and to populate association fields on a newly created Datum, allowing controllers to pass the current equipment context into the workflow."}, {"Operation": "DataOperations::AlertOperation", "Description": "After creating a Datum the service calls this operation to trigger alerting or other side effects, keeping notification logic out of the model and controller."}], "file": "app/services/opc_manager/find_or_create_datum.txt"}
{"Summary": "The OpcManager::DatumReviewAttributes service centralizes the preparation of a datum's permitted attributes by using the provided equipment (its device_type) to decide how to merge and transform fields and by calling the AddTimeZone operation to normalize timestamps and extended header dates, so controllers can simply call this service to receive ready-to-save, timezone-correct attributes without embedding conversion or device-specific logic.", "Relationships": [{"Model": "Equipment", "Description": "The service uses the equipment instance (especially equipment.device_type) to determine how extended_header and datum timestamps should be adjusted; controllers can pass an equipment and params to this service to obtain merged, device-aware attributes for persistence or further processing."}, {"Operation": "AddTimeZone", "Description": "The service delegates all timestamp and date adjustments to AddTimeZone.call for start_time, end_time, and extended_header entries, keeping timezone conversion centralized and reusable so controllers do not need to perform or duplicate that logic."}], "file": "app/services/opc_manager/datum_review_attributes.txt"}
{"Summary": "The OpcManager::Readyflux::ChartFlowrateData service encapsulates paginated, metric-specific querying and result shaping for flowrate charting from a supplied query result set so controllers can request ready-to-render data without embedding pagination or item-selection logic, keeping those concerns out of models and controllers.", "Relationships": [], "file": "app/services/opc_manager/readyflux/chart_flowrate_data.txt"}
{"Summary": "The OpcManager::Readyflux::ChartPermeateData service centralizes the logic to filter, slice, and count permeate analyte measurements (perm_vt, ce102, ph, uv) from a provided query result based on request parameters and offsets so controllers can call it to obtain paginated, chart-ready data without embedding query or pagination logic in controllers or models.", "Relationships": [{"Operation": "OpcManager::Readyflux::ChartPermeateData", "Description": "This service accepts a results relation, params, and an offset and returns per-analyte paginated result sets and first-page totals; controllers can invoke it to prepare data for chart rendering instead of performing filtering, selecting, and pagination themselves."}], "file": "app/services/opc_manager/readyflux/chart_permeate_data.txt"}
{"Summary": "Service classes like OpcManager::Readyflux::ChartPressureData centralize the data-selection, slicing, pagination, and structuring logic for pressure and temperature series so controllers can simply call the service and receive chart-ready datasets while the underlying models or query relations provide the raw measurement records, keeping controllers and models focused and thin.", "Relationships": [{"Operation": "OpcManager::Readyflux::ChartPressureData", "Description": "This service accepts a query/result relation and request params, filters the relation by specific item names (pt111, pt112, pt113, tmp, perm_vt), selects and aliases time and value fields, applies a fixed limit and offset to paginate slices, computes total counts when offset is zero, and returns a structured hash of series and totals for controllers to render charts or return API responses."}], "file": "app/services/opc_manager/readyflux/chart_pressure_data.txt"}
{"Summary": "The OpcManager::Readyflux::ChartTankRecirculationData service centralizes the filtering, slicing, and packaging of tank recirculation metric rows (feed_bag_weight, te161, ce101) so controllers can request paginated chart data without embedding query or pagination logic in controllers or models.", "Relationships": [{"Model": null, "Description": "This service reads request parameters to decide which metric series to fetch, applies a fixed slice size and offset for pagination, optionally computes total counts for the first slice, and returns a structured hash of series data and maxima that controllers can use to render or paginate chart data.", "Operation": "OpcManager::Readyflux::ChartTankRecirculationData"}], "file": "app/services/opc_manager/readyflux/chart_tank_recirculation_data.txt"}
{"Summary": "The OpcManager::Xuri::ChartTempPhData service centralizes selection, pagination, and format-choice logic for temperature and pH datasets (post-run, real-time, or Unicorn), delegating Unicorn-specific preparation to a dedicated operation so controllers can request ready-to-use chart data without embedding query, pagination, or formatting details.", "Relationships": [{"Operation": "OpcManager::PrepareUnicornData", "Description": "The service calls this operation to aggregate and format hourly Unicorn data slices (and to compute total sizes when needed), so controllers can obtain preprocessed Unicorn-ready datasets by invoking the service rather than handling aggregation themselves."}], "file": "app/services/opc_manager/xuri/chart_temp_ph_data.txt"}
{"Summary": "The OpcManager::Xuri::ChartGasesData service centralizes selection, slicing, pagination, and total-count calculation for CO2, O2, and DO measurements and setpoints across post-run, real-time, and unicorn sources, keeping source-specific logic out of controllers and delegating unicorn-specific data preparation to a dedicated operation so controllers can request ready-to-chart data slices from one place.", "Relationships": [{"Operation": "OpcManager::PrepareUnicornData", "Description": "ChartGasesData delegates unicorn-specific data transformation and slicing to OpcManager::PrepareUnicornData to produce paged sensor arrays and totals; controllers can call the service to get unicorn-formatted slices without handling that transformation themselves."}], "file": "app/services/opc_manager/xuri/chart_gases_data.txt"}
{"Summary": "The ChartRockingData service centralizes selection, aggregation, and pagination of rock speed and rock angle setpoint data from post-run, unicorn, or real-time result sources, delegating unicorn-specific preparation to an operation and providing a single, controller-friendly entry point so controllers can request ready-to-render chart datasets while underlying models/queries supply the records.", "Relationships": [{"Operation": "OpcManager::PrepareUnicornData", "Description": "ChartRockingData delegates unicorn-specific aggregation and pagination to this operation to build hour-based rock speed and rock angle setpoint datasets; controllers can call the service and rely on it to use this operation when unicorn data is required."}], "file": "app/services/opc_manager/xuri/chart_rocking_data.txt"}
{"Summary": "The OpcManager::Xuri::ChartMassData service centralizes mass-data fetching, slicing, and pagination for different data sources (post-run, real-time, unicorn), delegating unicorn-specific aggregation to an operation so controllers can request ready-to-use chart slices without handling the data preparation themselves.", "Relationships": [{"Model": null, "Description": "ChartMassData calls this operation to prepare and aggregate unicorn (hourly) mass data and to compute total counts for requested fields, encapsulating unicorn-specific transformation so the service can assemble final chart-ready results.", "Operation": "OpcManager::PrepareUnicornData"}], "file": "app/services/opc_manager/xuri/chart_mass_data.txt"}
{"Summary": "AktaFluxManager::ChartPressureData is a service that queries a provided results relation for selected pressure streams, builds paginated datasets and total counts for each stream, and returns a ready-to-use structure so controllers can get chart data and handle pagination without putting query or formatting logic in controllers or models.", "Relationships": [{"Operation": "AktaFluxManager::ChartPressureData", "Description": "This service accepts a queryable results collection, an offset, and params specifying which pressure types to include, runs filtered and limited queries for feed, permeate, retentate, and temporary pressures, computes total counts when needed, and returns the sliced result sets and counts; controllers can call it to obtain formatted, paginated pressure data for chart endpoints and UI pagination."}], "file": "app/services/akta_flux_manager/chart_pressure_data.txt"}
{"Summary": "AktaFluxManager::ChartFlowRateData is a service that centralizes query, slicing, and pagination logic for multiple flow-rate and flux measurement series so controllers can request chart-ready datasets and totals without embedding query or pagination logic in controllers or models; its purpose is to prepare paginated, labeled measurement series for visualization or API responses.", "Relationships": [{"Operation": "AktaFluxManager::ChartFlowRateData", "Description": "The service accepts a prefiltered results relation and user parameters, selects and slices specific measurement item_name series (permeate_flow_rate, feed_pump_flow_rate, permeate_pump_flow_rate, transfer_pump_flow_rate, permeate_flux), applies a fixed slice size and offset for pagination, computes total counts when appropriate, and returns labeled datasets and counts that a controller can call to populate charts or API responses without handling raw queries or pagination itself."}], "file": "app/services/akta_flux_manager/chart_flow_rate_data.txt"}
{"Summary": "The AktaFluxManager::ChartMassTempData service centralizes the selection, slicing, pagination, and formatting of tank_level, temperature, and mixer_speed time-series data so controllers can pass a query result and params to receive chart-ready data and optional total counts, demonstrating a separation where services hold processing logic, models supply raw query results, and controllers orchestrate usage and responses.", "Relationships": [{"Model": null, "Description": "This operation encapsulates the business logic for preparing mass and temperature chart data: it conditionally queries the provided results for tank_level, temperature, and mixer_speed, paginates the slices, and returns a structured hash so controllers do not need to implement filtering, slicing, or count calculations themselves.", "Operation": "AktaFluxManager::ChartMassTempData"}], "file": "app/services/akta_flux_manager/chart_mass_temp_data.txt"}
